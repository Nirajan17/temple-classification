{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13420dd3",
   "metadata": {},
   "source": [
    "### Learning to make a tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3a4bd70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled images: 1639\n"
     ]
    }
   ],
   "source": [
    "# creating tfrecord file\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Define the paths to your image folders\n",
    "folder_paths = {\n",
    "    'Bhaktapur-Durbar-Square': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Bhaktapur-Durbar-Square',\n",
    "    'Bouddanath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Bouddanath',\n",
    "    'Pashupatinath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Pashupatinath',\n",
    "    'Patan-Durbar-Square': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Patan-Durbar-Square',\n",
    "    'Swyambunath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Swyambunath'\n",
    "}\n",
    "\n",
    "class_mapping = {\n",
    "    'Bhaktapur-Durbar-Square': 0,\n",
    "    'Bouddanath': 1,\n",
    "    'Pashupatinath': 2,\n",
    "    'Patan-Durbar-Square': 3,\n",
    "    'Swyambunath': 4\n",
    "}\n",
    "\n",
    "# Define the output TFRecord file name\n",
    "output_directory = '/Users/nirajanpaudel17/Documents/Python/Major-Project'\n",
    "output_filename = os.path.join(output_directory, 'labeled_temples_images.tfrecord')\n",
    "\n",
    "# Initialize an empty list to store the labeled images\n",
    "labeled_images = []\n",
    "\n",
    "# Iterate over each class folder\n",
    "for class_name, folder_path in folder_paths.items():\n",
    "    \n",
    "    # Get the list of image filenames in the current class folder\n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    \n",
    "    class_label = class_mapping[class_name]\n",
    "    \n",
    "\n",
    "    # Iterate over each image in the class folder\n",
    "    for image_filename in image_filenames:\n",
    "        # Create the full path to the image file\n",
    "        image_path = os.path.join(folder_path, image_filename)\n",
    "\n",
    "        try:\n",
    "            # Read the image file\n",
    "            image = tf.io.read_file(image_path)\n",
    "\n",
    "            # Decode the image file\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "            \n",
    "            image = tf.io.encode_jpeg(image).numpy()\n",
    "\n",
    "\n",
    "            # Create a labeled example\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "                'class': tf.train.Feature(int64_list=tf.train.Int64List(value=[class_label]))\n",
    "            }))\n",
    "\n",
    "            # Append the labeled example to the list\n",
    "            labeled_images.append(example)\n",
    "\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print('Skipping unsupported image:', image_path)\n",
    "\n",
    "# Create a writer for the TFRecord file\n",
    "with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "    # Write each labeled example to the TFRecord file\n",
    "    for example in labeled_images:\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "# # Print the number of labeled images\n",
    "print('Number of labeled images:', len(labeled_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5f625263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3) tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'class': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)  # Modify the decoding function as per image format\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "#     label = tf.cast(example['class'], tf.string)\n",
    "    label = example['class']\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Specify the path to the TFRecord file(s)\n",
    "tfrecord_files = ['/Users/nirajanpaudel17/Documents/Python/Major-Project/labeled_temples_images.tfrecord']\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "\n",
    "# dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "# print(\"Dataset size:\", dataset_size)\n",
    "\n",
    "# Apply parsing function to the dataset\n",
    "dataset = dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Print the first few examples in the dataset\n",
    "for image, label in dataset.take(1):\n",
    "    # Process or use the image and label as needed\n",
    "    print(image.shape, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4eee1eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1311\n",
      "Test set size: 328\n"
     ]
    }
   ],
   "source": [
    "# # Shuffle the dataset\n",
    "# dataset = dataset.shuffle(buffer_size=1000, seed=42)\n",
    "\n",
    "# # Get the number of samples in the dataset\n",
    "# num_samples = int(1639)\n",
    "\n",
    "# # Split the dataset into train and test sets\n",
    "# train_size = int(0.8 * num_samples)  # 80% for training\n",
    "# test_size = num_samples - train_size\n",
    "\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# test_dataset = dataset.skip(train_size)\n",
    "\n",
    "# # Print the number of samples in each set\n",
    "# print(\"Train set size:\", train_size)\n",
    "# print(\"Test set size:\", test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9305f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_train = []\n",
    "labels_of_train = []\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    \n",
    "    images_to_train.append(image)\n",
    "    labels_of_train.append(label)\n",
    "    \n",
    "images_to_test = []\n",
    "labels_of_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    \n",
    "    images_to_test.append(image)\n",
    "    labels_of_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1f4b9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use the Xception model \n",
    "\n",
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image) \n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7122c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = preprocess(images_to_train,labels_of_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5070557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "n_classes = 5\n",
    "base_model = keras.applications.xception.Xception(include_top=False,weights='imagenet')\n",
    "# this excludes the global average pooling layer and the dense output layer.\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes,activation='softmax')(avg)\n",
    "model = keras.models.Model(inputs=base_model.input,outputs=output)\n",
    "\n",
    "\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.2, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0226ef04",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tnfenv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:959\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    960\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    " history = model.fit(x=train_images,y=train_labels,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "16365770",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers: \n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cf3af662",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.2, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "478d7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  history = model.fit(train_set,\n",
    "#                         steps_per_epoch=int(35),\n",
    "#                         validation_data=test_set,\n",
    "#                         validation_steps=int(7),\n",
    "#                         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba0e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0536493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")\n",
    "\n",
    "# images_resized = tf.image.resize(images_to_train, [224, 224])\n",
    "\n",
    "# # resnest requires image size of [224,224]\n",
    "\n",
    "# # images_resized[0].shape\n",
    "\n",
    "# # resnet provides a preprocess function to make the images compatible with it. Also, pixel range from 0 to 255\n",
    "\n",
    "# inputs = keras.applications.resnet50.preprocess_input(images_resized * 255) \n",
    "\n",
    "# Y_proba = model.predict(inputs)\n",
    "\n",
    "# import numpy as np\n",
    "# np.argmax(Y_proba[100])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # plt.imshow(images_to_train[100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
