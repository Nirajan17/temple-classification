{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13420dd3",
   "metadata": {},
   "source": [
    "### Learning to make a tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a4bd70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled images: 1639\n"
     ]
    }
   ],
   "source": [
    "# creating tfrecord file\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Define the paths to your image folders\n",
    "folder_paths = {\n",
    "    'Bhaktapur-Durbar-Square': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Bhaktapur-Durbar-Square',\n",
    "    'Bouddanath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Bouddanath',\n",
    "    'Pashupatinath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Pashupatinath',\n",
    "    'Patan-Durbar-Square': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Patan-Durbar-Square',\n",
    "    'Swyambunath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Swyambunath'\n",
    "}\n",
    "\n",
    "# Define the output TFRecord file name\n",
    "output_directory = '/Users/nirajanpaudel17/Documents/Python/Major-Project'\n",
    "output_filename = os.path.join(output_directory, 'labeled_temples_images.tfrecord')\n",
    "\n",
    "# Initialize an empty list to store the labeled images\n",
    "labeled_images = []\n",
    "\n",
    "# Iterate over each class folder\n",
    "for class_name, folder_path in folder_paths.items():\n",
    "    \n",
    "    # Get the list of image filenames in the current class folder\n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    \n",
    "\n",
    "    # Iterate over each image in the class folder\n",
    "    for image_filename in image_filenames:\n",
    "        # Create the full path to the image file\n",
    "        image_path = os.path.join(folder_path, image_filename)\n",
    "\n",
    "        try:\n",
    "            # Read the image file\n",
    "            image = tf.io.read_file(image_path)\n",
    "\n",
    "            # Decode the image file\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "            \n",
    "            image = tf.io.encode_jpeg(image).numpy()\n",
    "\n",
    "\n",
    "            # Create a labeled example\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "                'class': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_name.encode()]))\n",
    "            }))\n",
    "\n",
    "            # Append the labeled example to the list\n",
    "            labeled_images.append(example)\n",
    "\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print('Skipping unsupported image:', image_path)\n",
    "\n",
    "# Create a writer for the TFRecord file\n",
    "with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "    # Write each labeled example to the TFRecord file\n",
    "    for example in labeled_images:\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "# # Print the number of labeled images\n",
    "print('Number of labeled images:', len(labeled_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f625263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3) tf.Tensor(b'Bhaktapur-Durbar-Square', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'class': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)  # Modify the decoding function as per image format\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    label = tf.cast(example['class'], tf.string)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Specify the path to the TFRecord file(s)\n",
    "tfrecord_files = ['/Users/nirajanpaudel17/Documents/Python/Major-Project/labeled_temples_images.tfrecord']\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "\n",
    "# dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "# print(\"Dataset size:\", dataset_size)\n",
    "\n",
    "# Apply parsing function to the dataset\n",
    "dataset = dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Print the first few examples in the dataset\n",
    "for image, label in dataset.take(1):\n",
    "    # Process or use the image and label as needed\n",
    "    print(image.shape, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00e63fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: -1\n",
      "Validation set size: 0\n",
      "Test set size: -1\n"
     ]
    }
   ],
   "source": [
    "# splitting the datset into train and test set\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=1000, seed=42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "\n",
    "num_samples = int(dataset.cardinality().numpy())\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.8 * num_samples)  # 80% for training\n",
    "val_size = int(0.1 * num_samples)  # 10% for validation\n",
    "test_size = num_samples - train_size - val_size  # Remaining 10% for testing\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset = dataset.take(train_size)\n",
    "remaining_dataset = dataset.skip(train_size)\n",
    "val_dataset = remaining_dataset.take(val_size)\n",
    "test_dataset = remaining_dataset.skip(val_size)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print(\"Train set size:\", train_size)\n",
    "print(\"Validation set size:\", val_size)\n",
    "print(\"Test set size:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb3d5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_train = []\n",
    "labels_of_train = []\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    \n",
    "    images_to_train.append(image)\n",
    "    labels_of_train.append(label)\n",
    "    \n",
    "images_to_test = []\n",
    "labels_of_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    \n",
    "    images_to_test.append(image)\n",
    "    labels_of_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2d69931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([300, 300, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c142b953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Pashupatinath'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_of_train[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")\n",
    "\n",
    "# images_resized = tf.image.resize(images_to_train, [224, 224])\n",
    "\n",
    "# # resnest requires image size of [224,224]\n",
    "\n",
    "# # images_resized[0].shape\n",
    "\n",
    "# # resnet provides a preprocess function to make the images compatible with it. Also, pixel range from 0 to 255\n",
    "\n",
    "# inputs = keras.applications.resnet50.preprocess_input(images_resized * 255) \n",
    "\n",
    "# Y_proba = model.predict(inputs)\n",
    "\n",
    "# import numpy as np\n",
    "# np.argmax(Y_proba[100])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # plt.imshow(images_to_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a4e929fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use the Xception model \n",
    "\n",
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image) \n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d1307db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = train_dataset.shuffle(1000).repeat()\n",
    "train_set = train_dataset.map(preprocess).batch(batch_size).prefetch(1)\n",
    "valid_set = val_dataset.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_dataset.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ab58edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "n_classes = 5\n",
    "base_model = keras.applications.xception.Xception(include_top=False,weights='imagenet')\n",
    "# this excludes the global average pooling layer and the dense output layer.\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes,activation='softmax')(avg)\n",
    "model = keras.models.Model(inputs=base_model.input,outputs=output)\n",
    "\n",
    "\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.2, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf2d944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 13:24:35.596862: W tensorflow/core/framework/op_kernel.cc:1805] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/jm/g978mxy128vghxxjgmlf7cfc0000gn/T/ipykernel_14922/1099152971.py\", line 1, in <module>\n      history = model.fit(train_set,\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1085, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to float is not supported\n\t [[{{node Cast_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_57254]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tnfenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/jm/g978mxy128vghxxjgmlf7cfc0000gn/T/ipykernel_14922/1099152971.py\", line 1, in <module>\n      history = model.fit(train_set,\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1085, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/Users/nirajanpaudel17/anaconda3/envs/tnfenv/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to float is not supported\n\t [[{{node Cast_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_57254]"
     ]
    }
   ],
   "source": [
    " history = model.fit(train_set,\n",
    "                        steps_per_epoch=int(0.75 * 1500 / batch_size),\n",
    "                        validation_data=valid_set,\n",
    "                        validation_steps=int(0.15 * 1500 / batch_size),\n",
    "                        epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c895f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52322a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
