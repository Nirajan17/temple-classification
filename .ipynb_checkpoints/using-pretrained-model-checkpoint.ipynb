{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13420dd3",
   "metadata": {},
   "source": [
    "### Learning to make a tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a4bd70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled images: 1639\n"
     ]
    }
   ],
   "source": [
    "# creating tfrecord file\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Define the paths to your image folders\n",
    "folder_paths = {\n",
    "    'Bhaktapur-Durbar-Square': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Bhaktapur-Durbar-Square',\n",
    "    'Bouddanath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Bouddanath',\n",
    "    'Pashupatinath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Pashupatinath',\n",
    "    'Patan-Durbar-Square': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Patan-Durbar-Square',\n",
    "    'Swyambunath': '/Users/nirajanpaudel17/Documents/Python/Major-Project/Image-Processing/Dataset/Swyambunath'\n",
    "}\n",
    "\n",
    "# Define the output TFRecord file name\n",
    "output_directory = '/Users/nirajanpaudel17/Documents/Python/Major-Project/Temple-Classification'\n",
    "output_filename = os.path.join(output_directory, 'labeled_temples_images.tfrecord')\n",
    "\n",
    "# Initialize an empty list to store the labeled images\n",
    "labeled_images = []\n",
    "\n",
    "# Iterate over each class folder\n",
    "for class_name, folder_path in folder_paths.items():\n",
    "    \n",
    "    # Get the list of image filenames in the current class folder\n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    \n",
    "\n",
    "    # Iterate over each image in the class folder\n",
    "    for image_filename in image_filenames:\n",
    "        # Create the full path to the image file\n",
    "        image_path = os.path.join(folder_path, image_filename)\n",
    "\n",
    "        try:\n",
    "            # Read the image file\n",
    "            image = tf.io.read_file(image_path)\n",
    "\n",
    "            # Decode the image file\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "            \n",
    "            image = tf.io.encode_jpeg(image).numpy()\n",
    "\n",
    "\n",
    "            # Create a labeled example\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "                'class': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_name.encode()]))\n",
    "            }))\n",
    "\n",
    "            # Append the labeled example to the list\n",
    "            labeled_images.append(example)\n",
    "\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print('Skipping unsupported image:', image_path)\n",
    "\n",
    "# Create a writer for the TFRecord file\n",
    "with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "    # Write each labeled example to the TFRecord file\n",
    "    for example in labeled_images:\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "# # Print the number of labeled images\n",
    "print('Number of labeled images:', len(labeled_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f625263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3) tf.Tensor(b'Bhaktapur-Durbar-Square', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'class': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)  # Modify the decoding function as per image format\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    label = tf.cast(example['class'], tf.string)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Specify the path to the TFRecord file(s)\n",
    "tfrecord_files = ['/Users/nirajanpaudel17/Documents/Python/Major-Project/labeled_temples_images.tfrecord']\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "\n",
    "# Apply parsing function to the dataset\n",
    "dataset = dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Print the first few examples in the dataset\n",
    "for image, label in dataset.take(1):\n",
    "    # Process or use the image and label as needed\n",
    "    print(image.shape, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b483eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: -1\n",
      "Test set size: tf.Tensor(-1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# splitting the datset into train and test set\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=1000, seed=42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "\n",
    "num_samples = int(dataset.cardinality().numpy())\n",
    "\n",
    "train_size = int(0.8 * num_samples)  # 80% for training\n",
    "test_size = dataset.cardinality() - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print(\"Train set size:\", train_size)\n",
    "print(\"Test set size:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "968bf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_train = []\n",
    "labels_of_train = []\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    \n",
    "    images_to_train.append(image)\n",
    "    labels_of_train.append(label)\n",
    "    \n",
    "images_to_test = []\n",
    "labels_of_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    \n",
    "    images_to_test.append(image)\n",
    "    labels_of_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc865687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([300, 300, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77613f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Pashupatinath'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_of_train[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77721793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 35s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a9a4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = tf.image.resize(images_to_train, [224, 224])\n",
    "\n",
    "# resnest requires image size of [224,224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1627637c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([224, 224, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_resized[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a135876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet provides a preprocess function to make the images compatible with it. Also, pixel range from 0 to 255\n",
    "\n",
    "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50432347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 09:24:02.746731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 19s 325ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_proba = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ed27cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(Y_proba[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9024cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(images_to_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9141fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use the Xception model \n",
    "\n",
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image) \n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d8dd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = train_dataset.shuffle(1000).repeat()\n",
    "train_set = train_dataset.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_dataset.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.xception.Xception(include_top=False,weights='imagenet')\n",
    "# this excludes the global average pooling layer and the dense output layer.\n",
    "avg = keras.layers.GlobalAveragePooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b8fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
